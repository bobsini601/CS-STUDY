---

## 📌 스핀락

<aside>
💡 임계 구역에 진입이 불가능할 때 진입이 가능할 때까지 루프를 돌면서 재시도하는 방식으로 구현된 락

</aside>

- 임계 구역 진입 전까진 루프를 계속 돌고있기 때문에 busy wating이 발생

```java
wait(S) {
	while(S<=0); // 자원이 없다면 while 루프를 돌며 대기함
	S--;         // 자원을 획득함.
}

signal(S) {
	S++;         // 자원을 해제
}
```

특정한 자원을 획득(Lock) 또는 해제(Unlock)를 통해 공유 자원에 대한 접근 권한을 관리하는 방법입니다. 권한을 획득하기 전까지는 CPU는 무의미한 코드를 수행하는 Busy Waiting 상태로 대기하고 있다가 접근 권한을 얻게 되면 내부 코드를 수행하고 종류 후 권한을 해제합니다.

상태가 획득, 권한 밖에 없기 때문에 공유 영역에서는 하나의 컴포넌트만 접근이 가능합니다. 그리고 획득(Lock) 또는 해제(Unlock)의 주체는 동일해야 합니다.

하나의 작업이 빠르게 수행될 수 있는 장점이 있지만 선점 기간 동안에는 다른 프로세스의 작업이 지연될 수 있는 오버 헤드도 존재하게 됩니다. 그렇기 때문에 짧게 수행할 수 있는 작업에 주로 사용됩니다.

## 📌 세마포어

<aside>
💡 멀티 프로그래밍 환경에서 다수의 프로세스나 스레드의 여러 개의 공유 자원에 대한 접근을 제한하는 방법

</aside>

MUTual EXclusion으로 상호 배제라고도 합니다. 획득(Lock) 또는 해제(Unlock) 상태가 있으며 스핀락과 같이 접근 권한을 획득할 때까지 Busy Waiting 상태에 머무르지 않고 Sleep 상태로 들어가며 Wakeup 되면 권한을 획득을 시도합니다. 뮤텍스의 경우엔 Locking 메커니즘으로 오직 하나의 스레드만이 동일 시점에 뮤텍스를 얻어 임계 구역(Critical Section)에 접근할 수 있습니다. 그리고 획득(Lock) 또는 해제(Unlock)의 주체는 동일해야 합니다.

> 이진 세마포어 (Binary semaphore)
> 
- 0또는 1 값만 가질 수 있는 세마포어입니다.
- 임계 구역 문제를 해결하는데 사용하며 자원이 하나이기 때문에 뮤텍스로도 사용할 수 있습니다.

> 개수 세마포어 (Counting semaphore)
> 
- 도메인이 0이상인 임의의 정수값인 세마포어입니다.
- 여러개의 자원을 가질 수 있으며 제한된 자원을 가지고 액세스 작업을 할때 사용합니다.

## 📌 뮤텍스

<aside>
💡 자원에 대한 접근을 동기화하기 위해 사용되는 상호 배제 기술

</aside>

스핀락과 뮤텍스와는 다르게 하나 이상의 스레드가 공유자원에 접근하도록 할 수 있습니다. 표현형은 정수로 표현하며 획득(Lock) 또는 해제(Unlock)가 아닌 값을 올리고 내리는 방식으로 사용합니다. 컴포넌트가 특정 자원에 접근할 때 semWait이 먼저 호출되어 임계 구역에 들어갈 수 있는지 확인을 합니다. 조건에 만족한다면 semWait을 빠져나와 임계 구역에 들어가게 되고 이후 semSignal이 호출되어 임계 구역을 빠져나오게 됩니다.

semWait 연산 : 세마포어의 값을 감소시킵니다. 만약 값이 음수가 되면 semWait을 호출한 스레드는 블록 되지만 음수가 아니라면 스레드는 작업을 수행합니다.

semSignal 연산 : 세마포어의 값을 증가시킵니다. 만약 값이 양수가 아니라면 semWait 연산에 의해 블록 된 스레드들을 wake 시킵니다.

뮤텍스는 Locking 메커니즘으로 락을 걸은 스레드만이 임계 영역을 나갈 때 락을 해제할 수 있습니다. 뮤텍스는 wait와 signal이라는 원자적 연산을 사용합니다.

다음은 뮤텍스를 사용하여 상호 배제를 구현한 예입니다.

```arduino
do {
  wait (mutex);

    // Critical section

  signal (mutex);

    // Remainder section
} while (TRUE);
```

잠금 메커니즘이라는 점은 스핀 락과 동일하나 권한을 획득할 때까지 busy waiting 상태에 머무르지 않고

sleep 상태로 들어가고 wakeup 되면 다시 권한 획득을 시도하는 sleep lock을 사용합니다.

### 🤜 **뮤텍스와 세마포어의 차이점**

- 세마포어의 경우 여러 개의 스레드가 접근할 수 있는 반면 /  뮤텍스의 경우 오직 1개의 스레드만 접근이 가능합니다.
- 세마포어는 현재 수행 중인 스레드가 아닌 다른 스레드가 세마포어 해제를 할 수 있지만 뮤텍스의 경우 획득하고 해제하는 주체가 동일해야 합니다.

## 📌 페이징과 세그멘테이션

### 들어가기 전에..

### 메모리 할당

메모리에 프로그램을 할당할 때는 시작에 메모리 위치, 메모리의 할당 크기를 기반으로 할당하는데, 연속 할당과 불연속 할당으로 나뉩니다.

### 연속 할당

<aside>
💡 메모리에 ‘연속적으로’ 공간을 할당하는 것

</aside>

> 고정 분할 방식
> 

메모리를 미리 나누어 관리하는 방식이며, 메모리가 미리 나뉘어 있기 때문에 융통성이 없습니다. 또한, 내부 단편화가 발생합니다.

> 가변 분할 방식
> 

매 시점 프로그램의 크기에 맞게 동적으로 메모리를 나눠 사용합니다. 내부 단편화는 발생하지 않고 외부 단편화는 발생할 수 있습니다.

이는 최초 적합 (first-fit), 최적 적합 (best-fit), 최악 적합(worst-fit)이 있습니다.

| 최초 적합 | 위쪽이나 아래쪽부터 시작해서 홀을 찾으면 바로 할당 |
| --- | --- |
| 최적 적합 | 프로세스의 크기 이상인 공간 중 갖아 작은 홀부터 할당 |
| 최악 적합 | 프로세스의 크기와 갖아 많이 차이가 나는 홀에 할당 |

### 불연속 할당

<aside>
💡 메모리를 동일한 크기의 페이지(보통 4KB)로 나누고 프로그램마다 페이지 테이블을 두어 이를 통해 메모리에 프로그램을 할당하는 것.

</aside>

### 🤜 페이징

<aside>
💡 프로세스를 일정 크기인 페이지로 잘라서 메모리에 적재하는 방식

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/0db2788a-9084-4775-977e-cebf80738ac4/Untitled.png)

- **프로세스의 주소공간을 동일한 크기의 페이지 단위로 나누고, 메모리는 동일한 크기의 Frame으로 나눠서 물리적 메모리에 불연속적으로 저장하는 방식**
- 메모리가 불연속적으로 할당되어 있기 때문에 메모리로 가기 전에 각 페이지의 실제 메모리 주소가 저장되어 있는 페이지 테이블에서 물리 주소로 변경되어야 한다.
- **내부 단편화** 가 발생한다.

> 👍 장점
> 
- 논리 메모리는 물리 메모리에 저장될 때 연속되어 저장될 필요가 없고 물리 메모리의 남는 프레임에 적절히 배치되기 때문에 외부 단편화가 생기지 않는다.

> 👎 단점
> 
- 내부 단편화 문제가 발생할 수 있다. 페이지 단위를 작게하면 해결할 수 있지만, 페이지 매핑 과정이 복잡해져 오히려 비효율적이다.

### 🤜 세그멘테이션

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/136a9a18-d0dd-4cd5-bd40-d408fe4dd918/Untitled.png)

- **프로세스의 주소공간을 서로 크기가 다른 논리적인 블록단위인 세그먼트로 분할하고 메모리에 배치하는 방식**
- 프로세스는 논리적인 블록단위 세그먼트로 Code, Data, Stack & Heap 으로 나눌 수 있다.
- 세그멘테이션도 페이징과 유사하게 세그먼트 테이블이 존재하지만, 각각의 세그먼트의 크기가 다르므로 limit 정보가 주어진다.
- **외부 단편화** 가 발생한다.

> 👍 **장점**
> 
- 내부 단편화 문제가 해소된다.
- 보호와 공유 기능을 수행할 수 있다. 프로그램의 중요한 부분과 중요하지 않은 부분을 분리하여 저장할 수 있고, 같은 코드 영역은 한 번에 저장할 수 있다.

> 👎 **단점**
> 
- 외부 단편화 문제가 생길 수 있다

### 🤜 **Paging vs Segmentation**

- Paging은 고정 크기를 가짐
- Segmentation은 가변 크기를 가짐
- Paging은 내부 단편화 발생 가능, Segmentation은 외부 단편화 발생 가능

## 📌 페이지 교체 알고리즘

요구 페이징에서 언급한 대로 프로그램 실행 시 모든 항목이 물리 메모리에 올라오지 않고, 프로세스 동작에 필요한 페이지만 요청하게 되는데 이때 페이지 부재(page fault)가 발생하게 되면, 원하는 페이지를 보조저장장치(하드웨어)에서 가져오게 된다. 하지만, 물리 메모리가 모두 사용중이라면, 페이지 교체가 이뤄져야한다.

### 🤜 FIFO (First In First Out)

<aside>
💡 가장 오래된 페이지를 교체

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/026d51f8-d573-464a-94e7-946d5137c7fa/Untitled.png)

- 구현이 간단하지만 성능은 좋지 않은 편이다.
- 들어온 시간을 저장하거나 올라온 순서를 큐를 이용해 저장할 수 있다.
- Belady`s Anomaly 현상이 발생할 수 있다.
    
    ```
    Belady`s Anomaly란 프레임의 개수가 많아져도 page-fault가 줄어들지 않고 늘어나는 현상을 말한다.직관적으로 생각해보면 프레임의 개수가 많아지면 page-fault가 줄어들어야 할텐데, FIFO 알고리즘을 사용하면 그렇지 않을 수 있다.
    ```
    

### 🤜 OPT(Optimal) 알고리즘

<aside>
💡 앞으로 가장 오랫동안 사용되지 않을 페이지를 교체

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/2addcd4f-15f4-4ddb-9db4-d53195725d71/Untitled.png)

- 모든 페이지 교체 알고리즘 중 page-fault 발생이 가장 적다.
- Belady`s Anomaly 현상이 발생하지 않는다.
- 프로세스가 앞으로 사용할 페이지를 미리 알아야한다.
- 실제로 구현하기 거의 불가능한 알고리즘이다.
- 실제로 사용하기 보다는 연구 목적을 위해 사용된다.

### 🤜 LRU (Least Recently Used)

<aside>
💡 가장 오랫동안 사용하지 않은 페이지를 교체하는 알고리즘이다.

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/068926fc-f907-4b1c-b719-ad023cb6122a/Untitled.png)

- 최적 알고리즘과 비슷한 효과를 낼 수 있다.
- 성능이 좋은 편이다.
- 많은 운영체제가 채택하는 알고리즘이다.
- 큐로 구현가능. 사용한 데이터를 큐에서 제거하여 맨 위로다시 올리고, 프레임이 모자랄 경우 맨 아래에 있는 데이터를 삭제
- 사용된 시간을 알수있는 부분을 저장하여 가장 오랫동안 참조되지 않는 데이터를 제거 (페이지마다 카운터 필요)
    
    ** 카운터 : 각 페이지별로 존재하는 논리적인 시계(Logical Clock)로, 해당 페이지가 사용될때마다 0으로 클리어 시킨 후 시간을 증가시켜 시간이 가장 오래된 페이지를 교체*
    
- 단점: 프로세스가 주기억장치에 접근할때마다 참조된 페이지 시간을 기록해야 하므로 막대한 오버헤드가 발생

### 🤜 LFU (Least Frequently Used)

<aside>
💡 가장 사용 빈도가 적은 페이지를 교체

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/60785504-7823-4d21-85c8-64f94e8130b2/Untitled.png)

- 교체 대상이 여러 개라면 가장 오랫동안 사용하지 않은 페이지를 교체한다.
- LRU는 직전 참조된 시점만을 반영하지만, LFU는 참조횟수를 통해 장기적 시간규모에서의 참조성향 고려할 수 있음
- 단점: 가장 최근에 불러온 페이지가 교체될 수 있음, 구현 더 복잡, 막대한 오버헤드

### 🤜 MFU (Most Frequently Used)

<aside>
💡 LFU와 반대로, 참고 횟수가 가장 많은 페이지를 교체

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/784d5db1-ada9-4145-af67-79637a9b6d70/Untitled.png)

• 가정: 가장 많이 사용된 페이지가 앞으로는 사용되지 않을 것이다

### 🤜 NUR(Not Used Recently)

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ef05b185-9343-466f-96f9-47ffe9cfcc6c/Untitled.png)

- LRU와 유사한 알고리즘으로, 가장 오랫동안 사용되지 않은 페이지를 교체한다.
- 이를 확인하기 위해서 참조비트와 변형비트를 사용한다.
- 참조 비트 : 페이지가 호출되지 않았을 때는 0, 호출되었을 때는 1
- 변형 비트 : 페이지 내용이 변경되지 않았을 때는 0, 변경되었을 때는 1
- 00인것이 가장 먼저 교체되버린다. (우선순위 : 참조비트>변형비트)
    
    ![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/70330456-1298-475d-96ea-d87caf2d3ce0/Untitled.png)
    

### 🤜 Clock Algorithm

![즉, 페이지가 참조되어 1이 되고, 한 바퀴 도는 동안 사용되지 않으면 0이 되고 다시 한 바퀴를 도는 동안 사용되지 않는 페이지는 참조되지 않았으므로 교체 대상 페이지로 선정하는 알고리즘입니다.](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8f5122ca-88d0-4c21-bf69-e7104bdd8807/Untitled.png)

즉, 페이지가 참조되어 1이 되고, 한 바퀴 도는 동안 사용되지 않으면 0이 되고 다시 한 바퀴를 도는 동안 사용되지 않는 페이지는 참조되지 않았으므로 교체 대상 페이지로 선정하는 알고리즘입니다.

- 하드웨어적인 자원을 통해 기존(LRU, LFU)알고리즘의 소프트웨어적인 운영 오버헤드를 줄인 방식
- LRU와 유사한 알고리즘으로, 각 페이지가 최근에 참조되었는지 여부를 활용한다.
- 페이지마다 reference bit을 갖고 있고, 초기에는 모두 0, 참조되면 1으로 변경된다.
- page replacement가 진행되면 한쪽 방향으로 page table을 참조하기 시작하면서 1비트를 만다면 0비트로 내리고 0비트를 만나면 해당 페이지가 replacement 대상이 된다.
- **가장 오랫동안 참조되지 않은 페이지를 찾을 수는 없지만, 가장 최근에 참조된 페이지는 피할 수 있다.**
- 시계 바늘이 한 바퀴 도는 동안 걸리는 시간만큼 페이지를 메모리에 유지시켜 페이지 부재율을 줄이도록 설계

## 📌 단편화

컴퓨터에서 프로그램을 실행하거나 작업을 할 때 컴퓨터는 메모리에 해당 프로그램을 올리고(적재) 실행을 하게 됩니다. 이때 주기억장치 상에서 빈번하게 기억 장소가 할당되고 반납됨에 따라 **메모리 공간이 작은 조각 공간**으로 나뉘게 될 경우, 사용 가능한 메모리가 충분함에도 불구하고 메모리 할당이 불가능한 상태가 발생하게 되는데, 이를 **메모리 단편화**라고 합니다.

메모리 단편화의 종류로는 **내부 단편화**와 **외부 단편화**가 있습니다.

### 🤜 내부 단편화 (Internal Fragmentation)

<aside>
💡 메모리를 나눈 크기보다 프로그램이 **작아서** 들어가지 못하는 공간이 많이 발생하는 현상

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/ac6f4acc-9f83-41a2-a910-422da855404c/Untitled.png)

• **주기억장치 내의 실행 프로그램보다 사용자 영역이 커서 메모리 할당 후 사용되지 않고 남아있는 공간을 의미**

### 🤜 외부 단편화 (External Fragmentation)

<aside>
💡 메모리를 나눈 크기보다 프로그램이 **커서** 들어가지 못하는 공간이 많이 발생하는 현상

</aside>

![Untitled](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7465c21a-8c28-42e3-aa73-538e081432b3/Untitled.png)

- **주기억장치 내의 사용자 영역보다 실행 프로그램이 커서 프로그램이 메모리가 할당되지 않고 남아있는 공간을 의미**
- **메모리가 할당되고 해제되는 작업이 반복적으로 일어날 때 발생**

### 🤜 외부 단편화 해결 방법 : 압축

<aside>
💡 압축 기법은 주기억장치 내 **분산되어 있는 단편화된 공간들을 통합**하여 하나의 커다란 빈 공간을 만드는 작업을 의미한다.

</aside>

![외부 단편화 발생 상황](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/7d32ed80-b676-465b-8ddb-add84051b8dd/Untitled.png)

외부 단편화 발생 상황

![압축](https://s3-us-west-2.amazonaws.com/secure.notion-static.com/8e9582cc-d5f0-415c-9a4f-26f1a37be58f/Untitled.png)

압축

# CS 면접 질문

### ***페이징 또는 세그멘테이션을 사용하는 이유는?***

프로그램을 실행하기 위해 코드를 디스크에서 메인 메모리로 적재하는 과정에서 단편화가 생길 수 밖에 없다. 이렇게 단편화가 많이 발생하면 사용하지 못하는 메모리 공간이 많아져 낭비가 되므로 최대한 피해야 한다. 최초 적합, 최적 적합, 압축 등의 방식을 통해 단편화를 해결할 수도 있지만, 메모리 계산의 비용이 적은 페이징 또는 세그멘테이션을 주로 사용한다.

### ***페이징의 특징은?***

페이징은 프로그램을 실행할 때, 코드를 메모리에 적재하기 위해 사용하는 기법이며, 불연속 메모리 관리 기법이라는 특징이 있다. 다시 말해 프로그램 전체가 메모리에 연속적으로 올라가 있는 것이 아니라 페이지라는 고정된 크기로 분할되어 올라가 있다. 또한, 페이징은 외부 단편화 문제를 해결할 수 있다.

### ***페이징과 세그멘테이션의 차이는?***

페이징과 세그멘테이션 모두 프로그램을 실행하기 위해 디스크에 있는 내용을 분할하여 메모리에 적재하는 불연속 메모리 관리 기법이다. 둘의 차이는 프로그램을 분할하는 방식이다. 페이징의 경우 프로그램을 같은 크기의 페이지로 분할하는 데에 비해, 세그멘테이션은 논리적 의미를 기준으로 세그먼트를 분할한다.

> ref
> 

---

[[CS 지식] 내가 공부하려고 만든 신입 개발자 면접 지식 모음집](https://cocoon1787.tistory.com/668)